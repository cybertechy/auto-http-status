# LLM Configuration for Auto HTTP Status Library
# Uncomment and set these values to enable LLM-powered analysis (Layer 5)

# Required: Your LLM API key
# LLM_API_KEY=your_llm_api_key_here

# Optional: Specific model to use (defaults to gpt-4o-mini)
# LLM_MODEL=gpt-4o-mini

# Optional: API URL (defaults to OpenAI's endpoint)
# LLM_API_URL=https://api.openai.com/v1/chat/completions
